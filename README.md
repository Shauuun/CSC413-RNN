# CSC413-RNN

## Introduction
This repository contains the implementation of a RNN model with attention mechanism for sentiment analysis on Yelp reviews (text classogocaton). The task being solved is to classify the reviews which are inputs, into positive (4-5 stars) or negative (1-2 stars). The input is a sequence of words represented as word embeddings, and the output is a probability distribution over the categories. In the model, we used an LSTM to learn sequential dependencies in the input text with a self-attention mechanism to weigh the importance of each word in the input sequence. The output is generated by passing the final hidden state of the LSTM through two fully connected layers with ReLU activation. Then, a final softmax layer is used to obtain the category probabilities.

## Model Figure
![image](https://user-images.githubusercontent.com/77242297/230280568-371ffc05-9019-4147-b126-791cbe1b22ef.png)

Preprocessing:
1. Data Augmentation (See data transformation)
2. Tokenizing the text and padding the sequences to ensure that they are of the same length
3. Update vocabulary
4. Convert input tokens into embedding vectors.

RNN:
1. A Self-Attention layer that computes attention weights and modifies the input embeddings accordingly. (https://atcold.github.io/pytorch-Deep-Learning/en/week12/12-3/)
2. An LSTM layer to process the input sequence and capture temporal dependencies. It addresses gradient explosion or vanishing issue.
3. Fully Connected layers to produce the final output.

Output:
Use threshold to the determine whether the review is positive or negative.

## Model Parameter
The hyperparameters used in the model are:
* Embedding dimension: 64
* Hidden dimension: 64
* Output dimension: 2
* Number of attention heads: 8
* Learning rate: 0.01
* Batch size: 32
* Number of epochs: 10


## Model Examples
There is a sentence in the training set "It is a little on the pricier side but for all the experience you get and the quality, it is worth it." and it is labelled as 0. For a negative review. But our model labels it as 1, a positive review. Though it's considered as unsuccessful labelling, the review itself is positive nonetheless. 'Went for lunch. Beef brisket sandwich was awesome. So juicy and tender. Pulled pork was was just as good!' Was labelled a 1 or a positive review. That was a successful prediction.

## Data Source
The souce of our data set comes from a Yelp dataset(https://www.yelp.com/dataset). The dataset contains over 6 million reviews, along with business and user information.

## Data Summary
Here are some summary statistics
1.	Average length of review:  550 (include any character)
2.	Average rating : 3.8 
3.	Number of reviews positive reviews (4-5 stars): 139314
4.	Number of reviews negative reviews (1-2 stars): 38038
5.	Total data : 200000


## Data Transformation
We read the original JSON file was read line by line, loads each line as a JSON object, extracts the text and star rating from the object. We saved the output into a text file in the format of "text"\t rating\n where text is the cleaned review text and rating is the star rating (1-5). We collected 200,000 reviews in total.

To make the model more robust and capable of handling a variety of inputs, we used data augmentation techniques on a randomly selected 40% of the training set. The first technique was synonym replacement, which involves replacing a word with its synonym to increase the diversity of the vocabulary in the dataset. The second technique was random word swap, which swaps the positions of two words to change the word order and syntax of the sentences. The third technique was word insertion, which involves inserting a word into the review text to add more context and complexity to the sentences. The final technique was word deletion, which deletes two words from the review text to simplify the sentences. These techniques were chosen to help the model generalize better and get a better understanding of text grammar and syntax.

## Data Split
The dataset was split into train (60%), validation (20%), and test sets (20%) using sklearn's train_test_split function. We used this split because we wanted a large dataset for training to identify details and patterns. The 20% validation is sufficient to fine tune and the 20% testing is sufficient to evaluate performance.

## Training Curve


## Hyperparameter Tuning
We tuned our hyperparameters by monitering the performance of our training and validation. To tune the learn_rate and batch_size, we looked at the speed at which the training accuracy and validation improved, the rate at which they improved, and the final training accuracy acheived. With respect to num_epochs, we tuned it by testing starting at around 10-20. It was noted that when we go higher than that, the model begins to overfit.

## Quantitative Measure
The model performance was evaluated by simply comparing the predicted class with the ground truth.

## Quantitative and Qualitative Results
The model achieved an accuracy of [] on the test set.

## Justification of Results

## Ethical Consideration
Our model is to provide restaurants with an automated system to analyze customer reviews to help them improve restaurant service and dining quality. However, there are potential ethical concerns regarding the misuse of our model. For example,if the training data is biased towards certain demographics or experiences, the model may not represent the experiences of all customers, leading to discriminatory or unfair outcomes when used to make decisions about restaurants. Moreover, there is a risk that the model may be misused by restaurant owners or others to manipulate ratings of their own businesses or competitors. This could harm consumers and erode trust in the Yelp platform.

## Authors
